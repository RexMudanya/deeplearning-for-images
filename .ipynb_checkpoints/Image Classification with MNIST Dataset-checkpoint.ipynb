{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Downloading dataset directly from their API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MNIST contains 60k training images and 10k testing images.\n",
    "x_train and x_test contain greyscale RGN codes(0-255)\n",
    "y_train aand y_test contains labels from 0 to 9 representing numbers as they actually are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb496e5cf60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visaualizing numbers with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "image_index = 7000 # any value up to 60,000\n",
    "\n",
    "print(y_train[image_index])\n",
    "\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get shape of dataset to channel it to the CNN\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "60,000 number of images in training data\n",
    "(28, 28) size of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Normalizing the images"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Array above is 3 dimensional, to use the dataset we need 4-dim numpy arrays\n",
    "Normalize data by dividing the RGB codes by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28, 1)\n",
      "Number of images x_train :  60000\n",
      "Number of images x_test :  10000\n"
     ]
    }
   ],
   "source": [
    "# reshaping array to 4-dim\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# avoid decimal points by changing values into float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# normalizing the RGB by div by max value\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('Number of images x_train : ', x_train.shape[0])\n",
    "print('Number of images x_test : ', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required Keras modules containing models and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "# create Sequential model and add layers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# flattening the 2D arrays for fully connected layers\n",
    "model.add(Flatten())\n",
    "# 1st dense layer\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "# last dense layer/ output layer where classification happens\n",
    "model.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "experiment with the 1st dense layer BUT \n",
    "last dense layer must have 10 neurons as we have 10 classes(0,1,2,...,9)\n",
    "experiment with : kernel size, pool size, activation functions, dropout rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling and fitting the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set the optimizer with a given loss function which uses a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 59s 977us/step - loss: 0.1995 - acc: 0.9401\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 57s 949us/step - loss: 0.0821 - acc: 0.9749\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 55s 912us/step - loss: 0.0566 - acc: 0.9826\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 58s 966us/step - loss: 0.0447 - acc: 0.9855\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 57s 956us/step - loss: 0.0356 - acc: 0.9881\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 59s 986us/step - loss: 0.0287 - acc: 0.9903\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 58s 972us/step - loss: 0.0260 - acc: 0.9915\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 57s 958us/step - loss: 0.0216 - acc: 0.9931\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 58s 962us/step - loss: 0.0201 - acc: 0.9933\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 59s 979us/step - loss: 0.0184 - acc: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb47fdad2b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model using training data\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy']\n",
    "             )\n",
    "model.fit(x=x_train, y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "experiment with the optimizer, loss function, metrics and epochs\n",
    "adam - outperforms other optimizers\n",
    "check if there is a differnt loss function for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 505us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0602097490285887, 0.9854]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evalute model using test data\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "98.5% accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted class:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# individual predictions\n",
    "image_index = 4444 # can change\n",
    "plt.imshow(x_test[image_index].reshape(28, 28))\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "\n",
    "print(\" predicted class: \",pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
